{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from efficient_probit_regression.datasets import Covertype\n",
    "from efficient_probit_regression.sampling import gibbs_sampler_probit\n",
    "from efficient_probit_regression import settings\n",
    "from efficient_probit_regression.sampling import leverage_score_sampling, compute_leverage_scores\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset = Covertype()\n",
    "X = dataset.get_X()\n",
    "y = dataset.get_y()\n",
    "n = dataset.get_n()\n",
    "d = dataset.get_d()\n",
    "beta_opt = dataset.get_beta_opt()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "min_size = 500\n",
    "max_size = 15000\n",
    "step_size = 500\n",
    "\n",
    "sizes = np.arange(start=min_size, stop=max_size+step_size, step=step_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "prior_mean = np.zeros(d)\n",
    "prior_cov = 10 * np.eye(d)\n",
    "\n",
    "samples_per_chain = 250\n",
    "\n",
    "samples = []\n",
    "leverage_scores = compute_leverage_scores(X)\n",
    "for cur_size in tqdm(sizes):\n",
    "    X_reduced, y_reduced, _ = leverage_score_sampling(\n",
    "        X=X, \n",
    "        y=y, \n",
    "        sample_size = cur_size, \n",
    "        augmented = True, \n",
    "        online = False, \n",
    "        round_up = True, \n",
    "        precomputed_scores = leverage_scores\n",
    "    )\n",
    "    cur_sample = gibbs_sampler_probit(\n",
    "        X=X_reduced, \n",
    "        y=y_reduced, \n",
    "        prior_mean=prior_mean, \n",
    "        prior_cov=prior_cov, \n",
    "        num_samples=samples_per_chain, \n",
    "        num_chains=4, \n",
    "        burn_in=100\n",
    "    )\n",
    "    samples.append({\n",
    "        \"size\": cur_size, \n",
    "        \"sample\": cur_sample\n",
    "    })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_list = []\n",
    "for cur_sample in samples:\n",
    "    cur_df = pd.DataFrame(cur_sample[\"sample\"], columns=[f\"beta_{i}\" for i in range(d)])\n",
    "    cur_df[\"size\"] = cur_sample[\"size\"]\n",
    "    df_list.append(cur_df)\n",
    "\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df.to_csv(settings.RESULTS_DIR / f\"{dataset.get_name()}_reduced_samples.csv\", index=False)\n",
    "\n",
    "df"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "d3307380142bd0d9ee15157aa1da5ccdecd2dcad986e3fbaeb540e49b07ab888"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}